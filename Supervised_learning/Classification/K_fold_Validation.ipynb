{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9aceca",
   "metadata": {},
   "source": [
    "# K_fold Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7cc29a",
   "metadata": {},
   "source": [
    "- It is a data partitioning strategy so that you can effectively use your dataset to build a more generalized model.\n",
    "\n",
    "- K-Fold is validation technique in which we split the data into k-subsets and the holdout method is repeated k-times where each of the k subsets are used as test set and other k-1 subsets are used for the training purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127855c3",
   "metadata": {},
   "source": [
    "# - Importing all required libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf32cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c637e",
   "metadata": {},
   "source": [
    "- Creating object of the digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbecdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905349e",
   "metadata": {},
   "source": [
    "- Here our dataset is in dictionary format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3210ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e95513",
   "metadata": {},
   "source": [
    "# About dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234d5e7",
   "metadata": {},
   "source": [
    "- The columns available in our dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0245bc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1af5e",
   "metadata": {},
   "source": [
    "- Description of dataset in contain as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba90e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ee6e5",
   "metadata": {},
   "source": [
    "- In below we have our all input values for dataset which we have to pass into our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec2231",
   "metadata": {},
   "source": [
    "- It has all 8*8 digits input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c79b92c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f53e3",
   "metadata": {},
   "source": [
    "- Below contain all about column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23cfc591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_0_0',\n",
       " 'pixel_0_1',\n",
       " 'pixel_0_2',\n",
       " 'pixel_0_3',\n",
       " 'pixel_0_4',\n",
       " 'pixel_0_5',\n",
       " 'pixel_0_6',\n",
       " 'pixel_0_7',\n",
       " 'pixel_1_0',\n",
       " 'pixel_1_1',\n",
       " 'pixel_1_2',\n",
       " 'pixel_1_3',\n",
       " 'pixel_1_4',\n",
       " 'pixel_1_5',\n",
       " 'pixel_1_6',\n",
       " 'pixel_1_7',\n",
       " 'pixel_2_0',\n",
       " 'pixel_2_1',\n",
       " 'pixel_2_2',\n",
       " 'pixel_2_3',\n",
       " 'pixel_2_4',\n",
       " 'pixel_2_5',\n",
       " 'pixel_2_6',\n",
       " 'pixel_2_7',\n",
       " 'pixel_3_0',\n",
       " 'pixel_3_1',\n",
       " 'pixel_3_2',\n",
       " 'pixel_3_3',\n",
       " 'pixel_3_4',\n",
       " 'pixel_3_5',\n",
       " 'pixel_3_6',\n",
       " 'pixel_3_7',\n",
       " 'pixel_4_0',\n",
       " 'pixel_4_1',\n",
       " 'pixel_4_2',\n",
       " 'pixel_4_3',\n",
       " 'pixel_4_4',\n",
       " 'pixel_4_5',\n",
       " 'pixel_4_6',\n",
       " 'pixel_4_7',\n",
       " 'pixel_5_0',\n",
       " 'pixel_5_1',\n",
       " 'pixel_5_2',\n",
       " 'pixel_5_3',\n",
       " 'pixel_5_4',\n",
       " 'pixel_5_5',\n",
       " 'pixel_5_6',\n",
       " 'pixel_5_7',\n",
       " 'pixel_6_0',\n",
       " 'pixel_6_1',\n",
       " 'pixel_6_2',\n",
       " 'pixel_6_3',\n",
       " 'pixel_6_4',\n",
       " 'pixel_6_5',\n",
       " 'pixel_6_6',\n",
       " 'pixel_6_7',\n",
       " 'pixel_7_0',\n",
       " 'pixel_7_1',\n",
       " 'pixel_7_2',\n",
       " 'pixel_7_3',\n",
       " 'pixel_7_4',\n",
       " 'pixel_7_5',\n",
       " 'pixel_7_6',\n",
       " 'pixel_7_7']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd2d77",
   "metadata": {},
   "source": [
    "- Images of each pixel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a27f356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bb8de",
   "metadata": {},
   "source": [
    "- Below contain the output of our input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb983387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757fab6",
   "metadata": {},
   "source": [
    "- Below The names of target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c3b2ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096af7bc",
   "metadata": {},
   "source": [
    "- Applying train test split on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ba01be",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04508171",
   "metadata": {},
   "source": [
    "- Now we will first apply 3 different types of algorithm on our digits dataset and check accuracy of each algorithm\n",
    "1. Logistic\n",
    "2. SVC\n",
    "3. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "227f4502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9730639730639731"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 7500)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e583cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865319865319865"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ba50b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da03ff",
   "metadata": {},
   "source": [
    "- Instead of run above 3 algorithm separately we creata a function in which we can pass any algorithm which gives us accuracy according to alogrithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b46b09",
   "metadata": {},
   "source": [
    "-  Creating function in which we have to pass 5 parameter including algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14c7dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf184c",
   "metadata": {},
   "source": [
    "- Score according to the logistic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "721dfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9730639730639731"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65b1bd",
   "metadata": {},
   "source": [
    "-  Score according to the SVC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0166628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865319865319865"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(svm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c7681",
   "metadata": {},
   "source": [
    "-  Score according to the Random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0132fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764309764309764"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c1d92",
   "metadata": {},
   "source": [
    "- importing Kfold from library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57d80021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea77e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f49dcafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9c393",
   "metadata": {},
   "source": [
    "- As below we apply stratified fold on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "881eaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608aba9",
   "metadata": {},
   "source": [
    "- Creating object of class StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "131f3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c401e",
   "metadata": {},
   "source": [
    "- Initialization of 3 empty list in which we append score of each algorithm according to number of split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a10b9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_score = []\n",
    "svm_score = []\n",
    "rf_score = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c932ef3",
   "metadata": {},
   "source": [
    "- Here we have define for loop which work till number of splits we provided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923cb12c",
   "metadata": {},
   "source": [
    "- As fold work index wise so we get values through its index in our training and testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9288642",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(digits.data, digits.target):\n",
    "    X_train, X_test = digits.data[train_index], digits.data[test_index]\n",
    "    y_train, y_test = digits.target[train_index], digits.target[test_index]\n",
    "    lr_score.append(get_score(lr, X_train, y_train, X_test, y_test))\n",
    "    svm_score.append(get_score(svm, X_train, y_train, X_test, y_test))\n",
    "    rf_score.append(get_score(rf, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3c0e1",
   "metadata": {},
   "source": [
    "- Below are the list after perfoming for loop for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf95e747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.925,\n",
       " 0.8777777777777778,\n",
       " 0.9387186629526463,\n",
       " 0.9331476323119777,\n",
       " 0.8969359331476323]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "330fac2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9611111111111111,\n",
       " 0.9444444444444444,\n",
       " 0.9832869080779945,\n",
       " 0.9888579387186629,\n",
       " 0.9387186629526463]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef3154b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333333,\n",
       " 0.9055555555555556,\n",
       " 0.9554317548746518,\n",
       " 0.958217270194986,\n",
       " 0.9192200557103064]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818eec0",
   "metadata": {},
   "source": [
    "- For selection of best algorithm first we have to calculate its average and then we can choose one algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2680c529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9143160012380068"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4f47eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632838130609718"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d6e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343515939337668"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558fc7e",
   "metadata": {},
   "source": [
    "- To avoid all above process we have below method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfa1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fb073",
   "metadata": {},
   "source": [
    "- It is function to use during the testing and validation phase of your machine learning model development.\n",
    "- This cross validation method gives you a better understanding of model performance over the whole dataset instead of just a single train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d15e04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550720fe",
   "metadata": {},
   "source": [
    "Parameter to pass for cross_val_score\n",
    "- estimator = algorithm\n",
    "- no. splits we want\n",
    "- input \n",
    "- output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24e9b8",
   "metadata": {},
   "source": [
    "It work as below\n",
    "\n",
    "- The dataset is split up according to these folds, where each fold has a unique set of testing data\n",
    "- A model is trained and tested for each fold\n",
    "- Each fold returns a metric for it's test data\n",
    "- The mean and standard deviation of these metrics can then be calculated to provide a single metric for the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da4880",
   "metadata": {},
   "source": [
    "- Below applying cross_val_score on different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0954550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.925     , 0.87777778, 0.93871866, 0.93314763, 0.89693593])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(max_iter=7500), digits.data, digits.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afaf5891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(), digits.data, digits.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e5d5522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93611111, 0.88611111, 0.95543175, 0.96100279, 0.91086351])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(), digits.data, digits.target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57952f32",
   "metadata": {},
   "source": [
    "-- Using parameter to check accuracy with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32c630be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87777778, 0.84444444, 0.89972145, 0.93314763, 0.84679666])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(kernel = 'sigmoid'), digits.data, digits.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42de6042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41111111, 0.45      , 0.454039  , 0.44846797, 0.47910864])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(gamma='auto'), digits.data, digits.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b1b3ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98055556, 0.95833333, 0.98328691, 0.98885794, 0.95821727])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(C = 10), digits.data, digits.target, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
